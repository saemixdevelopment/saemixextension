\chapter{The {\sf saemix} package} \label{sec:package}

This chapter presents the input and output of the \monolix package. You will find the details of the settings and options in here for reference, but readers who wish to apply the methods quickly can directly skip to chapter~\ref{sec:examples} to find detailed examples of running the package.

Section~\ref{sec:usingsaemix} explains how to use the \monolix library and the many settings that can be tuned, while section~\ref{sec:techystuff} contains some technical details on the structure of the package and the architecture of the main S4 classes and methods.

\section{Inputs and outputs} \label{sec:usingsaemix}

\subsection{The inputs}

To summarise, \monolix~requires to define the model and to fix some parameters used for the algorithms. First, it is necessary to define:
\begin{itemize}
\item the structural model, that is the regression function $f$ defined in (\ref{nlme}),
\item the covariate model, that is the structure of the matrix $\fixed_effect$ defined in (\ref{prior}) and the covariates $(\covariate_i)$.
\item the variance-covariance model for the random effects, that is the structure of the variance-covariance matrix $\IIV$ defined in (\ref{prior}).
\item the residual variance model, that is the regression function $g$.
\end{itemize}
The only mandatory elements for a \monolix~fit are:
\begin{itemize}
\item a data object, defined by at least: 
   \begin{itemize}
   \item the name of the data file
   \item we advise to also specify the names of the columns containing the grouping variable, the predictor(s) and the response, although the program will attempt to recognise suitable columns
   \end{itemize}
\item a model object, defined by at least:
   \begin{itemize}
   \item the name of a valid model function
   \item the matrix of starting values \texttt{psi0}
      \begin{itemize}
      \item if no covariates are present in the model, a single line is sufficient, which will contain the starting values for the fixed effects $\mu$ in the model
      \item if covariates are present in the model: if \texttt{psi0} has more than 1 line, the next lines are assumed to represent the starting values for the covariate models (only parameters actually present in the model will be estimated, even if \texttt{psi0} contains non-null values; otherwise, values of 0 will be assumed.
      \end{itemize}
   \end{itemize}
\end{itemize}

Then, it is necessary to specify several parameters for running the algorithms:
\begin{itemize}
\item the SAEM algorithm requires to specify
\begin{itemize}
\item the initial values of the fixed effects $\fixed_effect_0$, the initial variance covariance matrix $\IIV_0$ of the random effects and the initial residual variance coefficients $\ag_0$, $\bg_0$ and $\cg_0$,
\item the sequence of step sizes $(\gamma_k)$, that is the numbers of iterations $(K_1,K_2)$ and the coefficients  $(a_1,a_2)$ defined in (\ref{stepsize1}) and (\ref{stepsize2}),
%\item the number of iterations $K_0$ used to estimate non random individual parameters.
\item the number of burning iterations $K_b$ used with the same value $\theta_0$ before updating the sequence $(\theta_k)$.
\end{itemize}
\item the MCMC algorithm requires to set
\begin{itemize}
\item the number of Markov Chains $L$,
\item the numbers $m_1$, $m_2$, $m_3$ and $m_4$ of iterations of the Hasting-Metropolis algorithm,
\item the probability of acceptance $\rho$ for  kernel $q^{(3)}$ and $q^{(4)}$,
\end{itemize}
\item the algorithm to estimate the conditional distribution of the $(\phig_i)$ requires to set
\begin{itemize}
\item the width of the confidence interval $\rho_{mcmc}$ (see (\ref{Lmcmc}),
\item the number of iterations $L_{mcmc}$.
\end{itemize}
\item the Simulated Annealing algorithm requires to set
\begin{itemize}
\item the coefficient $\tau_1$ and $\tau_2$ defining the decrease of the temperature (see (\ref{tau1},\ref{tau2}))
\item the number of iterations $K_{sa}$.
\end{itemize}
\item the Importance Sampling algorithm requires to set
\begin{itemize}
\item the Monte Carlo number $M$ used to estimate the observed likelihood (see (\ref{islike})).
\end{itemize}
\item the Gaussian Quadrature algorithm requires to set
\begin{itemize}
\item the number of quadrature points $N_{QG}$ used to compute each integral (see (\ref{sec:gqlike}))
\item the width of each integral $N_{QG}$
\end{itemize}
\end{itemize}

In the \R~implementation of \monolix, most of these parameters, as well as other variables used by the algorithm, are set through a list which is included in the object returned by an \monolix~fit. Table~\ref{tab:options} shows the correspondance between the parameters and the elements in this list.
\begin{center}
\begin{longtable}{r p{8cm} p{3cm} c}
\hline {\bf Parameter} & {\bf Meaning} & {\bf Option name} & {\bf Default value}\\
\hline
\endfirsthead
\multicolumn{4}{l}{{\itshape \bfseries \tablename\ \thetable{} -- cont.}} \\
\hline {\bf Parameter} & {\bf Meaning} & {\bf Option name} & {\bf Default value}\\
\hline
\endhead
\hline \multicolumn{4}{r}{{-- {\it To be continued}}} \\ 
\endfoot
%\hline
\endlastfoot
& & \\
\hline
$L$ & number of Markov Chains & {\sf nb.chains} & 1$^*$ \\
$K_1, K_2$ & Number of iterations during the two periods & {\sf nbiter.saemix} & c(300,100)\\
$K_b$ & Number of burning iterations & {\sf nbiter.burn} & 5 \\
$m_1, m_2, m_3$ & Number of iterations of kernels $q^{(2)}$, $q^{(3)}$ and $q^{(4)}$ at each iteration of SAEM& {\sf nbiter.mcmc} & c(2,2,2)\\
 & Number of iterations during which simulated annealing is performed & {\sf nbiter.sa} &  \\
$\rho$ & Probability of acceptance for kernels $q^{(2)}$ and $q^{(3)}$ & {\sf proba.mcmc} & 0.4 \\
 & Stepsize for kernels $q^{(2)}$ and $q^{(3)}$ & {\sf stepsize.rw} & 0.4 \\
 & Initial variance parameters for kernels $q^{(2)}$ and $q^{(3)}$ & {\sf rw.init} & 0.5\\
$\tau$ & Parameter controlling cooling in the Simulated Annealing algorithm & {\sf alpha.sa} & 0.97 \\
$M$ & Number of Monte-Carlo samples used to estimate the likelihood by Importance Sampling & {\sf nmc.is} & 5000 \\
$\nu$ & Number of degrees of freedom of the Student distribution used for the estimation of the log-likelihood by Importance Sampling & {\sf nu.is} & 4 \\
$K_{GQ}$ & Number of nodes used for Gaussian Quadrature & {\sf nnodes.gq} & 12 \\
 & Width of the distribution used for Gaussian Quadrature (in SD) & {\sf nsd.gq} & 4 \\
$L_{mcmc}$ & Number of iterations required to assume convergence for the conditional estimates & {\sf ipar.lmcmc} & 50\\
$\rho_{mcmc}$ & Confidence interval for the conditional mean and variance & {\sf ipar.rmcmc} & 0.95 \\
\multicolumn{2}{l}{Other variables} \\
& Algorithms to be run in a call to {\sf saemix()}: a vector of 3 values of 0/1, representing respectively individual parameter estimates (MAP), estimation of the Fisher information matrix and estimation of the LL by importance sampling  & {\sf algorithms} & c(1,1,1) \\
& Plot graphs during the estimation of the LL by IS & {\sf print.is} & \false \\
 & Maximum number of iterations for the estimation of fixed effects & {\sf maxim.maxiter} & 100\\
& Whether convergence plots should be drawn at regular intervals during the estimation & {\sf displayProgress}& \true \\
& Interval (in number of iterations) between two convergence plots & {\sf nbdisplay} &  \\
& Seed to initialise the random number generator & {\sf seed} & 123456 \\
\hline
\\
\caption{Parameters set as options in the {\sf options} list. To set an option, one would define it as an element of this list (see examples), and any option not defined by the user is automatically set to its default value.} \label{tab:options}
\end{longtable} 
\par \kern -1cm{\itshape $^*$ the default number of chains is 1, except when the number of subjects is smaller than 50, where it defaults to $n_c$ where $n_c$ is the smallest integer such that $n_c\;N \geq 50$}
\end{center}


Assuming the result of the \monolix~fit has been stored in an object {\sf saemix.fit}, the list of options can be accessed using the following instruction (see section~\ref{sec:saemixS4} for more details on how to access elements of objects in \R):
\begin{verbatim}
saemix.fit["options"]
\end{verbatim}
For example, to see the number of chains, one would type in \R:
\begin{verbatim}
saemix.fit["options"]$nb.chains
\end{verbatim}

The easiest way to set options is to pass them in a list when calling the main fitting function, as can be seen in the example section (section~\ref{sec:exampletheo}).

\clearpage
\subsection{The outputs}

In the \R~implementation of \monolix, the object returned after a call to the main fitting function {\sf saemix()} contains the following elements:
\begin{itemize}
\item data: the data object, created by a call to the {\sf saemixData()} function, and containing the dataset to be used in the analysis
\item model: the model object, created by a call to the {\sf saemixModel()} function, and containing the model characteristics
\item options: a list containing the options for the estimation algorithm (see above)
\item prefs: a list containing the graphical preferences for plots, which will be described in the next section
\item results: the results object
\item rep.data: the replicated data (when available)
\item sim.data: the simulated data (when available)
\end{itemize}
Assuming the result of a call to {\sf saemix()} has been ascribed to the object \verb+yfit+, these elements can be accessed, for example for the results element, with the following command:
\begin{verbatim}
yfit["results"]
\end{verbatim}
The results object is an object of class {\sf SaemixRes}. Most users will not need to access the elements since functions have been created to output the results. However, elements of the results object can also be accessed individually; for example, the likelihood estimated by importance sampling can be accessed as:
\begin{verbatim}
yfit["results"]["ll.is"]
\end{verbatim}
More details on S4 structures (objects and methods), and on how to access the elements of S4 objects can be found in~\ref{sec:techystuff}.

Table~\ref{tab:resSlots} shows the most important elements present in the results object (some of these are only present after a call to a specific function, or when the proper option has been set; for instance, estimates of individual parameters are only estimated when the first element of the {\sf algorithm} element in {\sf options} is 1).
\begin{center}
\begin{longtable}{r p{12cm}}
\hline {\bf Element} & {\bf Meaning}\\
\hline
& \\
\endfirsthead
\multicolumn{2}{l}{{\itshape \bfseries \tablename\ \thetable{} -- cont.}} \\
\hline {\bf Element} & {\bf Meaning}\\
\hline
& \\
\endhead
\hline \multicolumn{2}{r}{{-- {\it To be continued}}} \\ 
\endfoot
%\hline
\endlastfoot
{\sf npar.est} & Number of parameter estimates \\
{\sf fixed.effects} & Estimates of the fixed effects \\ 
{\sf se.fixed} & Standard errors of estimation of the fixed effects\\
{\sf respar} & Estimates of the parameters of the residual error model \\ 
{\sf se.repar} & Standard errors of estimation of the residual parameters\\
{\sf omega} & Estimates of the fixed effects \\ 
{\sf se.omega} & Standard errors of the estimation of the fixed effects\\
{\sf ll.is} & Log-likelihood estimated by importance sampling\\
{\sf aic.is} & AIC using the log-likelihood estimated by importance sampling \\
{\sf bic.is} & BIC using the log-likelihood estimated by importance sampling \\
{\sf ll.lin} & Log-likelihood estimated by linearisation\\
{\sf aic.lin} & AIC using the log-likelihood estimated by linearisation \\
{\sf bic.lin} & BIC using the log-likelihood estimated by linearisation \\
{\sf ll.gq} & Log-likelihood estimated by gaussian quadrature\\
{\sf aic.gq} & AIC using the log-likelihood estimated by gaussian quadrature \\
{\sf bic.gq} & BIC using the log-likelihood estimated by gaussian quadrature \\
{\sf map.psi} & Individual estimates of the parameters ($\psi$), obtained as the mode of the conditional distribution (MAP)\\
{\sf map.phi} & Estimate of the corresponding individual $\phi$\\
{\sf map.eta} & Estimate of the corresponding random effect \\
{\sf map.shrinkage} & Shrinkage for the MAP estimates \\
{\sf cond.mean.psi} & Individual estimates of the parameters, obtained as the mean of the conditional distribution \\
{\sf cond.mean.phi} & Estimate of the corresponding individual $\phi$\\
{\sf cond.mean.eta} & Estimate of the corresponding random effect \\
{\sf cond.var.phi} & Estimate of the variance of the individual $\phi$ \\
{\sf cond.shrinkage} & Shrinkage for the conditional estimates \\
%{\sf phi} & Individual parameters simulated in the different chains during the algorithm \\
%{\sf mean.phi} & Average of the individual parameters simulated in the different chains during the algorithm\\
{\sf phi.samp} & Samples from the individual conditional distribution of the $\phi$\\
{\sf phi.samp.var} & Variance of the samples from the individual conditional distribution of the $\phi$\\
{\sf ypred} & Population predictions, computed for the mean population parameters $ypred_{ij}= f\left(x_{ij} ; h\left( \mathbb{E}_{\hat{\theta}}(\phigi) \right) \right)$ \\
{\sf ppred} & Population mean predictions, obtained as the expectation of the predictions $ppred_{ij}= \mathbb{E}_{\hat{\theta}}(f(x_{ij} ; \psigi) ))$\\
{\sf ipred} & Individual predictions, computed using the MAP estimates of the individual parameters \\
{\sf icpred} & Individual predictions, computed using the conditional estimates of the individual parameters \\
{\sf wres} & Weighted population residuals, computed using {\sf ppred} (see section~\ref{section_wres}) \\
{\sf pd} & Prediction discrepancies \\
{\sf npde} & Normalised prediction distribution errors \\
{\sf iwres} & Individual weighted residuals, using the MAP estimates of the individual parameters (using the same computations as ipred) \\
{\sf icwres} & Individual weighted residuals using the conditional estimates of the individual parameters (using the same computations as icpred) \\

{\sf } & \\
\hline
\\
\caption{Elements contained in the results object.} \label{tab:resSlots}
\end{longtable} 
\end{center}
A full list of all the elements in a results object can be obtained by the command:
\begin{verbatim}
getSlots("SaemixRes")
\end{verbatim}

% ECO TODO: pourquoi on garde phi et mean.phi à la fin, ne faudrait-il pas les virer des outputs ? ou bien garder phi sur toutes les chaînes ?

\noindent {\bf a) Estimation of the parameters:}

The SAEM algorithm computes the maximum likelihood estimate $\hthetag$ and estimates its covariance matrix $I({\hthetag})^{-1}/N$ using the Fisher Information Matrix, as defined in Section~\ref{sec_fish}.

Recall that $d$ is the number of individual parameters, then for $j=1,2\ldots d$, we can
\begin{enumerate}
\item estimate the vector of fixed effects $\fixed_effect$ (intercept and coefficients of the covariates) by $(\hat{\fixed_effect})$,
\item estimate the standard errors of $\fixed_effect$,
\item test if some components of $\fixed_effect$ are null by computing the significance level of the Wald test.
\end{enumerate}

Let $\IIV=(\omega_{jl}, 1\leq j,l \leq d)$. Then, for any $j,l=1,2\ldots d$, we can
\begin{enumerate}
\item estimate $\omega_{jl}$ by $\homega_{jl}$, for all $1\leq j,l \leq d$,
\item estimate the standard error of $\homega_{jl}$, for all $1\leq j,l \leq d$,
%\item test ``$\omega_{jl}=0$", by computing the significance level of the Wald test.
\end{enumerate}
%(In this version of \monolix, the standard errors of the non diagonal elements $\homega_{jl}$, with $j\neq l$, are not computed and the Wald test is only performed for the diagonal elements of $\IIV$).

\noindent {\bf b) Estimation of the conditional distributions:}

The MCMC algorithm provides an estimation of the conditional means, conditional modes and conditional standard deviations of the individual parameters and of the random effects. 

The function can be called with an argument {\sf nsamp} which runs several sampling chains in parallel, providing several independent samples from the individual conditional distribution for each subject. The number of iterations necessary to obtain convergence (that is, for the successive empirical conditional mean and sd to remain within the requested precision for all chains) is reported, and if the option {\sf displayProgress} is \true, plots are produced during the estimation process showing the evolution of the different sampling chains.

\begin{itemize}
\item the conditional mode can be found in \monolix~in the results component of the object, as {\sf map.psi} (there is also a \texttt{map.phi} component for the corresponding $\phi$ and a \texttt{map.eta} for the random effects)
\item the conditional expectation can be found in {\sf cond.mean.psi} and the variance in {\sf cond.var.psi} (the corresponding $\phi$ and $\eta$ are also available)
\end{itemize}

\noindent {\bf c) Estimation of the likelihood:}

The \monolix~algorithm can provide three different approximations to the likelihoods, through importance sampling, linearisation or gaussian quadrature. 

%The Importance Sampling algorithm computes an estimate $ \ell_M(\yg;\hthetag)$ of the observed likelihood together with its standard error.

\noindent {\bf d) Hypothesis testing and model selection:} 

We can test the covariate model, the covariance model and the residual error model.

The AIC and BIC criteria are defined by
\begin{eqnarray}
	AIC &= - 2 \log \ell_M(\yg;\hthetag) + 2 P \\
	BIC &= - 2 \log \ell_M(\yg;\hthetag) + \log(N) P \label{BICN}
\end{eqnarray}
where $P$ is the total number of parameters to be estimated and $N$ is the number of subjects. Note that the BIC defined using this formula is in fact the corrected BIC (BICc) proposed by Raftery to better account for the information in mixed-effect models~\cite{Raftery95}; it differs from the traditional BIC which uses a factor $\log(N_{tot})$ instead of $\log(N)$. The same formula is also used in {\sc Monolix}.

A specific version of BIC can be used for the comparison of covariate models with fixed covariance structure of the random effects~\cite{DelattrePoursatLavielle2014}:
\begin{equation} 
BIC_h =- 2 \log \ell_M(\yg;\hthetag) + \log(N) P_R + \log(N_{tot}) P_F \label{BICh}
\end{equation}
where $P_R$ (resp.$P_F$) is the number of estimated parameters in $\fixed_effect$ that are related to the covariate effects on the random (resp. non random) components of the individual parameters. It is important to note that $BIC_h$ is not appropriate if the compared models do not share the same covariance model.  

Joint covariate and random effects selection often leads to the definition of many candidate models whose exhaustive comparison by an information criterion such as AIC or BIC is not possible in a reasonable time. An alternative approach is to use stepwise methods. The algorithm proposed in~\cite{DelattrePoursat2020} follows such idea by iteratively combining the classical BIC~\eqref{BICN} and the hybrid BIC~\eqref{BICh} for covariance and covariate model selection respectively.
 
When comparing two nested models ${\cal M}_0$ and ${\cal M}_1$ with dimensions $P_0$ and $P_1$ (with $P_1>P_0$), the Likelihood Ratio Test uses the test statistic 
$$LRT = 2 ( \log \ell_{M,1}(\yg;\hthetag_1) -  \log \ell_{M,0}(\yg;\hthetag_0) )$$
According to the hypotheses to test, the limiting distribution of $LRT$ under the null hypothesis is either a $\chi ^2$ distribution, or a mixture of a $\chi^2$ distribution and a
$\delta-Dirac$ distribution. For example:
\begin{itemize}
	\item[-] to test whether some fixed effects are null, assuming the same covariance structure of the random effects, one should use
	$$LRT \limite{N\to \infty}{} \chi^2(P_1-P_0) $$
	\item[-] to test whether some correlations of the covariance matrix $\IIV$ are null, assuming the same covariate model, one should use 
	$$LRT \limite{N\to \infty}{} \chi^2(P_1-P_0) $$
	\item[-] to test whether the variance of one of the random effects is zero, assuming the same covariate model, one should use
	$$LRT \limite{N\to \infty}{} \frac{1}{2} \chi^2(1) + \frac{1}{2}\delta_0 $$
\end{itemize}


\noindent {\bf e) Estimation of the weighted residuals:}

The Population Weighted Residuals $(PWRES_{ij})$,  the Individual Weighted Residuals $(IWRES_{ij})$ and the Normalised Prediction Distribution Errors $(\npde_{ij})$ are computed as described Section~\ref{section_wres}.

\newpage
\subsection{Plots} \label{sec:plot.functions}

The generic function {\sf plot.saemix} can be used to obtain a number of plots used to assess and diagnose the model. This function is called using the following arguments:
\begin{verbatim}
plot(saemix.fit,plot.type="plot.type")
\end{verbatim}
where {\sf saemix.fit} is the object returned after a successful call to {\sf saemix}, and {\sf "plot.type"} is the type of plot chosen. The following plot types are available:
\begin{itemize}
\item "data": spaghetti plot of the data
\item "convergence": a plot of the convergence graphs; this is the default type when {\sf type} is not given
\item "likelihood": estimate of the likelihood through importance sampling versus the number of MCMC samples
\item "individual.fit": plot of the individual fits overlayed on the data, for each subject in the dataset
\item "population.fit": plot of the fits obtained with the population parameters and the individual covariates and design, overlayed on the data, for each subject in the dataset% ECO TODO: a enlever ?
\item "both.fit": plot of the individual and population fits, overlayed on the data % ECO TODO: a enlever ?
\item "observations.vs.predictions": observations versus predictions(left: population predictions, right: individual predictions)
\item "random.effects": boxplot of the random effects. With the option "m", a horizontal line is added representing the estimate of the population parameter
\item "parameters.versus.covariates": plot of a parameter versus all covariates in the model (uses the individual estimates); for continuous covariates, a scatterplot is produced, while for categorical covariates a boxplot is shown. With the option "m", a horizontal line is added representing the estimate of the population parameter. With the options "l" or "s", a curve representing a linear regression ("l") or a spline regression ("s") is added. Several options can be combined (see below) %ECO TODO ou dataset ?
\item "randeff.versus.covariates": plot of a random effect versus all covariates in the model (uses the individual estimates) %ECO TODO ou dataset ?
\item "correlations": matrix of scatterplot showing the correlations between pairs of random effects (uses the individual estimates)
\item "marginal.distribution": distribution of the random effects
\item "residuals.distribution": distribution of the standardised residuals, computed using the population predictions (weighted residuals), the individual predictions (individual weighted residuals) and optionally if available the $\npde$. Both histograms and QQ-plots of the residuals are given
\item "residuals.scatter": scatterplot of standardised residuals versus the predictor (X) and versus the predictions. The residuals are computed using the population predictions (weighted residuals), the individual predictions (individual weighted residuals) and optionally if available the $\npde$. The corresponding predictions are the individual predictions for individual residuals, and population predictions for $\npde$ and population residuals
\item "vpc": Visual Predictive Check; prediction intervals can be added to the plots. To produce prediction intervals, different methods are available for binning (grouping points), which can be selected through the {\sf vpc.method} argument:
\begin{itemize}
\item[{\sf equal}:] the quantile of the data are used to define the breaks, yielding a similar number of points in each interval;
\item[{\sf width}:] bins of equal width (if the option {\sf xlog} is set to \true, the bins will be of equal width on the logarithmic scale);
\item[{\sf user}:] user-defined breaks (set as the vector in {\sf vpc.breaks} argument; it is possible to give only the inner breaks or to include the boundaries (min/max));
%\item[{\sf optimal}:] an optimal binning algorithm which uses clustering techniques to group the data appropriately and performs better for unbalanced designs~\cite{Lavielle11} (not implemented yet); the algorithm uses a penalised criterion with a parameter {\sf vpc.lambda} that can be tuned by the user.
\end{itemize}
In the first three methods, there will be at most {\sf vpc.bin} bins, and the boundaries of each interval, as well as the value used to plot the corresponding point, will be shown.
\item "npde": plots of the $\npde$ (distribution, histogram, and scatterplots versus the regression variable and versus predictions), as displayed in the $\npde$ library~\cite{CometsCMPB08}. Tests comparing the empirical distribution of the $\npde$ to the theoretical $\mathcal{N}(0,1)$ distribution by a combined test are also displayed.
\end{itemize}
Several plots can be produced by setting {\sf plot.type} to be a vector. Partial matching will be used (so that {\sf plot.type="individual"} will produce individual fits, but {\sf plot.type="residuals"} will produce an error message because it could correspond to two different types of plots). After a successful fit, if the option {\sf save.graphs} is \true, the following plots are produced by default and saved to a file named {\sf diagnostic\_graphs.ps} in the directory containing fit results: spaghetti plot of the data, convergence plots, likelihood by importance sampling, plots of predictions versus observations for population and individual estimates, boxplots of the random effects, correlation between the random effects. Individual fits are also saved, in a separate file called {\sf individual\_fits.ps}. Some of these plots may be missing if the corresponding estimates have not been requested (eg if the likelihood has not been computed by importance sampling, the plot won't be available).

%ECO TODO
% décrire options des graphes

\bigskip Each plot can also be obtained individually using a specific function, which allows total flexibility over the layout, including options to change plotting symbols, colors, or which subjects are to be used. Table~\ref{tab:plot.functions} gives the names of the individual functions corresponding to the plots listed above.
 \begin{table}[!h]
\begin{center}
\begin{tabular}{r p{10cm}}
\hline Plot function name & Brief description\\
\hline
{\sf saemix.plot.data()} & Spaghetti plot of the data \\
{\sf saemix.plot.convergence()} & Convergence plots for all estimated parameters \\
{\sf saemix.plot.llis()} & Plot of the log-likelihood estimated by importance sampling \\
{\sf saemix.plot.obsvspred()} & Plot of the predictions versus the observations \\
{\sf saemix.plot.fits()} & Individual fit \\
{\sf saemix.plot.distpsi()} & Estimated distribution of the random effects \\
{\sf saemix.plot.randeff()} & Boxplot of a random effect \\
{\sf saemix.plot.parcov()} & Plot of parameters versus covariates \\
{\sf saemix.plot.randeffcov()} & Plot of random effects versus covariates \\
{\sf saemix.plot.scatterresiduals()} & Scatterplots of residuals versus predictor and predictions \\
{\sf saemix.plot.distribresiduals()} & Plot of the distribution of the residuals \\
{\sf saemix.plot.vpc()} & Visual Predictive Check \\
{\sf saemix.plot.npde()} & Plots of the npde \\
%{\sf } &  \\
\hline
\end{tabular}
\caption{Names of the individual functions used to obtain each type of plot. Please refer to the inline help for the arguments to provide to each function.} \label{tab:plot.functions}
\end{center}
\par \kern -0.5cm
\end{table} 

A help page describing these plots is available in the inline help:
\begin{verbatim}
?saemix.plot.data
\end{verbatim}

%\newpage
\par \kern -0.5cm
A common argument to all the functions is a list of options. This list can be set using the function {\sf saemix.plot.setoptions()}, and it is automatically set during the fit by {\sf saemix()} and stored in the Slot {\sf prefs} of the object. The options can then be modified through this list, for instance changing the new default color to red for all plots is done by setting the attribute {\sf col} in the list:
\begin{verbatim}
saemix.fit["prefs"]$col<-"red"
\end{verbatim}
Options can also be set on the fly for a given plot, by simply adding it to the call to {\sf plot()} as an argument (see examples in section~\ref{sec:exampletheo}):
\begin{verbatim}
plot(saemix.fit,plot.type="data",col="red",main="Raw data")
\end{verbatim}

The list of options that can be changed are given in table~\ref{tab:plot.options}, along with their default value. Not all options apply to all graphs.
%\newpage
%\begin{table}[!h]
\begin{center}
\begin{longtable}{r p{8cm} p{3cm}}
\hline {\bf Parameter} & {\bf Description} & {\bf Default value}\\
\hline
\endfirsthead
\multicolumn{3}{l}{{\itshape \bfseries \tablename\ \thetable{} -- cont.}} \\
\hline {\bf Parameter} & {\bf Description} & {\bf Default value}\\
\hline
\endhead
\hline \multicolumn{3}{r}{{-- {\it To be continued}}} \\ 
\endfoot
%\hline
\endlastfoot

& & \\
\multicolumn{3}{l}{{\itshape \bfseries General graphical options}} \\
{\sf ask} & Whether users should be prompted before each new plot (if \true) & \false \\
{\sf new} & Whether a new plot should be produced  & \true \\
{\sf interactive} & Whether users should be prompted before predictions or simulations are performed (if \true) & \false \\
{\sf mfrow} & Page layout (NA: layout set by the plot function or before) & NA \\
{\sf main} & Title & empty \\
{\sf xlab} & Label for the X-axis & empty \\
{\sf ylab} & Label for the Y-axis & empty \\
{\sf type} & Type of the plot (as in the \R~plot function) & b (lines and symbols) \\
{\sf col} & Main symbol color & black \\
{\sf xlog} & Scale for the X-axis (\true: logarithmic scale) & \false \\
{\sf ylog} & Scale for the Y-axis (\true: logarithmic scale) & \false \\
{\sf cex} & A numerical value giving the amount by which plotting text and symbols should be magnified relative to the default & 1 \\
{\sf cex.axis} & Magnification to be used for axis annotation relative to the current setting of 'cex' & 1 \\
{\sf cex.lab} & Magnification to be used for x and y labels relative to the current setting of 'cex' & 1 \\
{\sf cex.main} & Magnification to be used for main titles relative to the current setting of 'cex' & 1 \\
{\sf pch} & Symbol type & 20 (dot) \\
{\sf lty} & Line type & 1 (straight line) \\
{\sf lwd} & Line width & 1 \\
{\sf xlim} & Range for the X-axis (NA: ranges set by the plot function) & NA \\
{\sf ylim} & Range for the Y-axis (NA: ranges set by the plot function) & NA \\
{\sf ablinecol} & Color of the horizontal/vertical lines added to the plots & "DarkRed" \\
{\sf ablinelty} & Type of the lines added to the plots & 2 (dashed) \\
{\sf ablinelwd} & Width of the lines added to the plots & 2 \\
& & \\
\multicolumn{3}{l}{{\itshape \bfseries Options controlling the type of plots}} \\
{\sf ilist} & List of subjects to include in the individual plots & all \\
{\sf level} & Level of grouping to use (0=population, 1=individual) & 0:1 \\
{\sf smooth} & Whether a smooth should be added to certain plots & \false \\
{\sf line.smooth} & Type of smoothing (l=line, s=spline) & s \\
{\sf indiv.par} & Type of individual estimates (map= conditional mode, eap=conditional mean) & map \\
{\sf which.par} & Which parameters to use for the plot & all \\
{\sf which.cov} & Which covariates to use for the plot  & all \\
{\sf which.pres} & Which type of residuals to plot at the population level (when level includes 0) & c("wres","npde") \\
{\sf which.resplot} & Type of residual plot ("res.vs.x": scatterplot & c("res.vs.x","res.vs.pred", \\
&  versus X, "res.vs.pred": scatterplot versus predictions, "dist.hist": histogram, "dist.qqplot": QQ-plot) & "dist.qqplot","dist.hist") \\
& & \\
\multicolumn{3}{l}{{\itshape \bfseries Specific graphical options}} \\
{\sf obs.col} & Symbol color to use for observations & black \\
{\sf ipred.col} & Symbol color to use for individual predictions & black \\
{\sf ppred.col} & Symbol color to use for population predictions & black \\
{\sf obs.lty} & Line type to use for observations & 1 \\
{\sf ipred.lty} & Line type to use for individual predictions & 2 \\
{\sf ppred.lty} & Line type to use for population predictions & 3 \\
{\sf obs.lwd} & Line width to use for observations & 1 \\
{\sf ipred.lwd} & Line width to use for individual predictions & 1 \\
{\sf ppred.lwd} & Line width to use for population predictions & 1 \\
{\sf obs.pch} & Symbol type to use for observations & 20 \\
{\sf ipred.pch} & Symbol type to use for individual predictions & 20 \\
{\sf ppred.pch} & Symbol type to use for population predictions & 20 \\
& & \\
\multicolumn{3}{l}{{\itshape \bfseries Options for marginal distribution}} \\
{\sf indiv.histo} & When \true, an histogram of the estimates of the individual parameters will be added to the plots of the distribution of the parameters & \false \\
{\sf cov.value} & The value for each covariate to be used to condition on for the marginal distribution (NA: median will be used) & NA \\
{\sf range} & Range (expressed in number of SD) over which to plot the marginal distribution & 3 \\
& & \\
\multicolumn{3}{l}{{\itshape \bfseries Graphical options for VPC and residual plots}} \\
{\sf vpc.method} & Method used to bin points (one of "equal", "width", "user" or "optimal"); at least the first two letters of the method need to be specified (the "optimal" method is not implemented yet) & "equal" \\
{\sf vpc.bin} & number of binning intervals & 10 \\
{\sf vpc.interval} & size of interval & 0.95 \\
{\sf vpc.breaks} & vector of breaks used with user-defined breaks (vpc.method="user") & NULL \\
{\sf vpc.lambda} & value of lambda used to select the optimal number of bins through a penalised criterion & 0.3 \\
{\sf vpc.pi} & whether prediction intervals should be plotted for the median and the limits of the VPC interval & \true \\
{\sf vpc.obs} & whether observations should be overlayed on the plot & \true \\
{\sf fillcol} & Color used to fill histograms (individual parameter estimates) or to plot intervals in standard VPC-type plots (VPC, pd, npde) & "lightblue1" \\
{\sf col.fillmed} & Color used to fill prediction intervals around the median (for VPC, pd, npde) & "pink" \\
{\sf col.fillpi} & Color used to fill prediction intervals around the limits of intervals (for VPC, pd, npde) & "slategray1" \\
{\sf col.lmed} & Color used to plot the median of simulated values (for VPC, pd, npde) & "indianred4" \\
{\sf col.lpi} & Color used to plot the simulated limit of prediction intervals (for VPC, pd, npde) & "slategray4" \\
{\sf col.pobs} & Color used to plot the symbols for observations (for VPC, pd, npde) & "steelblue4" \\
{\sf col.lobs} & Color used to plot the line corresponding to given percentiles of observations (for VPC, pd, npde) & "steelblue4" \\
{\sf lty.lmed} & Line type used to plot the median of simulated values (for VPC, pd, npde) &  2 \\
{\sf lty.lpi} & Line type used to plot the simulated limit of prediction intervals (for VPC, pd, npde) & 2 \\
{\sf lty.lobs} & Line type used to plot the line corresponding to given percentiles of observations (for VPC, pd, npde) & 1 \\
{\sf lwd.lmed} & Line width used to plot the median of simulated values (for VPC, pd, npde) &  2 \\
{\sf lwd.lpi} & Line width used to plot the simulated limit of prediction intervals (for VPC, pd, npde) & 1 \\
{\sf lwd.lobs} & Line width used to plot the line corresponding to given percentiles of observations (for VPC, pd, npde) & 2 \\
& & \\
\multicolumn{3}{l}{{\itshape \bfseries Specific graphical options}} \\
{\sf pcol} & Main symbol color & black \\
{\sf lcol} & Main line color & black \\
{\sf } &  &  \\
\hline
\\
\caption{Default graphical parameters. Any option not defined by the user is automatically set to its default value.} \label{tab:plot.options}
\end{longtable} 
\end{center}
%\end{table} 
